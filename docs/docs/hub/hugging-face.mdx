---
title: Hugging Face
description: Cortex supports all `GGUF` and `ONNX` models available in Huggingface repositories, providing access to a wide range of models.
---

import Tabs from "@theme/Tabs";
import TabItem from "@theme/TabItem";

:::warning
ðŸš§ Cortex.cpp is currently under development. Our documentation outlines the intended behavior of Cortex, which may not yet be fully implemented in the codebase.
:::


Cortex.cpp supports all `GGUF` and `ONNX` models from the [Hugging Face Hub](https://huggingface.co), along with its built-in models. For `TensorRT-LLM` models, only built-in models in the [Cortex Model Repos](/docs/hub/cortex-hub) are supported.

:::info
To pull a supported model from HuggingFace, use the format `ORG_ID/MODEL_ID`.
:::
## GGUF
![HF GGUF](/img/docs/gguf.png)
To view all available `GGUF` models on HuggingFace, select the `GGUF` tag in the Libraries section.
<Tabs>
  <TabItem value="MacOs/Linux" label="MacOs/Linux">
  ```sh
    # Stable
    ## Pull the Codestral-22B-v0.1-GGUF model from the bartowski organization
    cortex pull bartowski/Codestral-22B-v0.1-GGUF

    # Pull the gemma-7b model from the google organization
    cortex pull google/gemma-7b

    # Beta
    ## Pull the Codestral-22B-v0.1-GGUF model from the bartowski organization
    cortex-beta pull bartowski/Codestral-22B-v0.1-GGUF

    # Pull the gemma-7b model from the google organization
    cortex-beta pull google/gemma-7b

    # Nightly
    ## Pull the Codestral-22B-v0.1-GGUF model from the bartowski organization
    cortex-nightly pull bartowski/Codestral-22B-v0.1-GGUF

    # Pull the gemma-7b model from the google organization
    cortex-nightly pull google/gemma-7b
  ```
  </TabItem>
  <TabItem value="Windows" label="Windows">
  ```sh
    # Stable
    ## Pull the Codestral-22B-v0.1-GGUF model from the bartowski organization
    cortex.exe pull bartowski/Codestral-22B-v0.1-GGUF

    # Pull the gemma-7b model from the google organization
    cortex.exe pull google/gemma-7b

    # Beta
    ## Pull the Codestral-22B-v0.1-GGUF model from the bartowski organization
    cortex-beta.exe pull bartowski/Codestral-22B-v0.1-GGUF

    # Pull the gemma-7b model from the google organization
    cortex-beta.exe pull google/gemma-7b

    # Nightly
    ## Pull the Codestral-22B-v0.1-GGUF model from the bartowski organization
    cortex-nightly.exe pull bartowski/Codestral-22B-v0.1-GGUF

    # Pull the gemma-7b model from the google organization
    cortex-nightly.exe pull google/gemma-7b
  ```
  </TabItem>
</Tabs>

## ONNX
![HF ONNX](/img/docs/onnx.png)
To view all available `ONNX` models on HuggingFace, select the `ONNX` tag in the Libraries section.
<Tabs>
  <TabItem value="MacOs/Linux" label="MacOs/Linux">
  ```sh
    # Stable
    ## Pull the XLM-Roberta-Large-Vit-B-16Plus model from the immich-app organization
    cortex pull immich-app/XLM-Roberta-Large-Vit-B-16Plus

    # Pull the mt0-base model from the bigscience organization
    cortex pull bigscience/mt0-base

    # Beta
    ## Pull the XLM-Roberta-Large-Vit-B-16Plus model from the immich-app organization
    cortex-beta pull immich-app/XLM-Roberta-Large-Vit-B-16Plus

    # Pull the mt0-base model from the bigscience organization
    cortex-beta pull bigscience/mt0-base

    # Nightly
    ## Pull the XLM-Roberta-Large-Vit-B-16Plus model from the immich-app organization
    cortex-nightly pull immich-app/XLM-Roberta-Large-Vit-B-16Plus

    # Pull the mt0-base model from the bigscience organization
    cortex-nightly pull bigscience/mt0-base
  ```
  </TabItem>
  <TabItem value="Windows" label="Windows">
  ```sh
    # Stable
    ## Pull the XLM-Roberta-Large-Vit-B-16Plus model from the immich-app organization
    cortex.exe pull immich-app/XLM-Roberta-Large-Vit-B-16Plus

    # Pull the mt0-base model from the bigscience organization
    cortex.exe pull bigscience/mt0-base

    # Beta
    ## Pull the XLM-Roberta-Large-Vit-B-16Plus model from the immich-app organization
    cortex-beta.exe pull immich-app/XLM-Roberta-Large-Vit-B-16Plus

    # Pull the mt0-base model from the bigscience organization
    cortex-beta.exe pull bigscience/mt0-base

    # Nightly
    ## Pull the XLM-Roberta-Large-Vit-B-16Plus model from the immich-app organization
    cortex-nightly.exe pull immich-app/XLM-Roberta-Large-Vit-B-16Plus

    # Pull the mt0-base model from the bigscience organization
    cortex-nightly.exe pull bigscience/mt0-base
  ```
  </TabItem>
</Tabs>

## TensorRT-LLM
We are still working to support all available `TensorRT-LLM` models on HuggingFace. For now, Cortex.cpp only supports built-in `TensorRT-LLM` models, which can be downloaded from the [Cortex Model Repos](/docs/hub/cortex-hub).
