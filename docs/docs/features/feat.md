---
title: Nitro Features 
description: What Nitro supports
keywords: [Nitro, Jan, fast inference, inference server, local AI, large language model, OpenAI compatible, open source, llama]
---

Nitro enhances the `llama.cpp` research base, optimizing it for production environments with advanced features:

### Ease of Use
- **1-Click Install**: Simplified setup process, making it accessible for non-technical users.
- **HTTP Interface**: Easy integration with no complex bindings required.

### Cross-Platform and Hardware Compatibility
- **Runs on Multiple OS**: Supports Windows, MacOS, and Linux.
- **Wide Hardware Support**: Compatible with arm64, x86 CPUs, and NVIDIA GPUs.

### Performance and Scalability
- **Separate Process Operation**: Runs independently, ensuring no interference with main app processes.
- **Multi-Threaded Server**: Capable of handling multiple users concurrently.
- **Efficient Binary Size**: Lightweight footprint with a small binary size (~3mb compressed).

### Developer and Industry Compatibility
- **OpenAI Compatibility**: Seamless integration with OpenAI models and standards.
- **No Hardware Dependencies**: Flexibility in deployment without specific hardware requirements.
